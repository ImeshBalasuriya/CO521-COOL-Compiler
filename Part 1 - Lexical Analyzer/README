README file for Programming Assignment 2 (C++ edition)
=====================================================

Your directory should contain the following files:

 Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [cool root]/src/PA2/lextest.cc
 mycoolc         -> [cool root]/PA2/mycoolc
 stringtab.cc    -> [cool root]/PA2/stringtab.cc
 utilities.cc    -> [cool root]/PA2/utilities.cc
 handle_flags.cc -> [cool root]/PA2/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[cool root]/PA2

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2
----------------

Single character tokens (=, +, -, *, /, ~, <, ,, :, ;, @, ., (, ), {, }): We have returned the ascii value of the character iteslf. 

Multiple character tokens (=>, <-, <=): We have returned the corresponding enumerated value for these tokens as defined in the 'cool-parse.h' file.

Keywords (CLASS, ELSE, IF, FI, THEN, IN, INHERITS, ISVOID, LET, LOOP, POOL, WHILE, CASE, ESAC, NEW, OF, NOT): In Cool, keywords are not case-sensitive.
Hence, the lexer was designed to match these keywords with a regular expression that disregards the case of the characters. After matching a keyword,
we have returned the corresponding enumerated value for the token as defined in the 'cool-parse.h' file.

Single-line comments: According to the cool specification, inline comments start with --, and are terminated at the end of the line.
We have defined a start condition named INLINECOMMENT, which would activate at the start of a comment, and from that point onwards, the
lexer will eat up any characters that are found within the comment until it meets a new line or if it is the end of file (EOF).

Nested comments: Cool also supports multiline comments with the ability to nest them. To implement this we have used another start condition named
NESTEDCOMMENT which will activate when the lexer meets a (*, indicating the start of a multiline comment. To ensure that nesting is possible, we
have setup a global variable nestCount, which is initialized to zero at the start of a multiline comment. Each subsequent (* token the lexer meets
will increment the nestCount variable. Then, meeting a *) token will decrement the nestCount and meeting a *) while nestCount is zero will
denote the end of the nested comment. In order to allow the comment to span multiple lines, the lexer will eat up any newline characters that it meets 
while in the NESTEDCOMMENT start condition. It must be noted that reaching EOF while in a nested comment is not allowed in Cool and hence
we have added an extra rule that generates the error "EOF in comment" if the lexer runs into EOF while in the NESTEDCOMMENT start condition.
Encountering a *) without having entered a multiline comment will also generate an error "Unmatched *)". 

String literals: 

Boolean literals (true, false): Cool allows Boolean literals to have both uppercase and lowercase characters as long as the starting character is lowercase (Eg: tRuE is allowed while TruE is not).
We defined a regex that matches the Boolean literals according to these conditions. Once the lexer matches a Boolean literal, it sets the 'boolean' property of cool_yylval to the
correspinding Boolean value of the literal and returns the BOOL_CONST enumerated value defined in the 'cool-parse.h' file.

Integer literals: Cool accepts non-empty strings of the digits 0-9 as integer literals. Therefore, an appropriate regex was defined to match such integers and 
once the lexer finds a match it sets the 'symbol' property of cool_yylval to the relevant string of digits and returns the INT_CONST enumerated value. To do this efficiently,
the provided 'inttable' string table was used to cross-reference matched integer literals. 

Type identifiers: Cool defines any string consisting of letters, digits and the _ character as a type identifier provided that the identifier begins with a capital letter.
Similar to integer literals, matched identifiers were added to the 'idtable' string table and passed onto the cool_yylval.symbol property and the TYPEID enumerated value was returned.

Object identifiers: Object identifiers are identical to type identifiers except that they have to begin with a lowercase letter. Hence, the implementation for object identifiers
differs from that of type identifiers only in the regex that is matched.

Whitespace (' ', '\n', '\r', '\f', '\t', '\v'): The lexer will eat up any insignificant whitespace it finds.  

Invalid characters: In the event the lexer encounters any token that does not match any of the above rules, it can be classified as an invalid character and an error message containing the 
invalid token is returned. This rule was added at the very end of the rule specification such that the lexer tries to match with this rule only if it fails to match any of the preceding rules.

Line numbers: The implemented lexer keeps track of line numbers as it scans the code. This is done by setting up a global variable 'curr_lineno' which is incremented every time the lexer encounters
a newline character in the code. It is important to note that this increment operation happens even in cases where the lexer generates an error.

	






